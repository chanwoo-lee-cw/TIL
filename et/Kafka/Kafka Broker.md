# Kafka Broker

## 카프카 브로커란?

> 데이터를 저장하고 모든 데이터 스트리밍 요청을 처리하는 서버
> 카프카 클러스터 내에서 실제 메세지를 저장, 검색 및 배포 그리고 클라이언트와의 통신을 담당한다.
> 각 브로커는 퍼블리셔의 데이터를 처리하고 컨슈머에게 데이터를 제공하며 파티션 및 오프셋 상태를 유지하는 서버.
>
> **즉, Kafka Broker는 카프카의 메세지를 저장하고, 프로듀서와 컨슈머로부터 메세지를 주고 받으며, 클러스터 내에서 파티션 리더 역할을 수행하는 단일 서버 프로세스.**



## 카프카 브로



## 카프카 브로커의 핵심 역할

### Message Handling

- **메세지 수신** : 
  - 프로듀서의 지정된 키(파티션을 결정적으로 결정하는 키)를 기반으로, 또는 라운드 로빈 선택을 통해 메세지를 주제 내에 배치할 파티션을 결정한다.
  - 컨슈머 그룹의 각 컨슈머는 해당 토픽의 파티션에서 글을 읽으며, 카프카 브로커는 어떤 컨슈머가 어떤 파티션에서 글을 읽고 있는지 추적한다. 이를 통해 부하와 메세지를 한 소비자에게만 전달되도록 한다.
- **Offsets 할당** : 
  - 각 파티션의 오프셋의 로그를 추적해서 어떤 메세지가 소비되었는지, 어떤 메세지가 소비되지 않았는지 파악한다. 오프셋을 추적하면 그룹내의 컨슈머들 사이에서 실패나 재조정이 발생했을 때, 컨슈머들이 중단했던 곳에서 이어서 할 수 있다.

### Consumer에게 서비스 제공

- **메세지 가져오기 :**
  - 소비자는 브로커에게 메세지를 요청하고, Topic, partition, Offset을 지정한다. 브로커는 요청한 메세지를 검색하여 제공한다.
- **Offsets 관리 :**
  - 브로커는 메세지의 오프셋을 추적하여 소비자가 데이터를 받을 수 있도록 하고, 실패시 다시 마지막 일기 위치에서 다시 시작할 수 있도록 한다.
- **컨슈머 관리 :**
  - 컨슈머 그룹이 해당 토픽을 요청했을때, 토픽을 컨슈머들 수만큼 토픽을 나눠서 분배한다. 각 파티션은 컨슈머 하나가 한 파티션을 담당하고, `heartbeat`를 통해 컨슈머가 죽었는지 확인하고, 죽었다면 남은 컨슈머에게 파티션을 재할당한다.

### 복제 및 내 결함성

- **데이터 복제 :**
  - 브로커는 고가용성과 내결함성을 보장하기 위해 여러 브로커에 걸쳐 파티션 데이터를 복제한다.
- **리더 선출 :**
  - 각 파티션마다 한명의 브로커가 리더 역할을 하며 모든 읽기 및 쓰기 요청을 처리하고 다른 브로커는 팔로워 역할을 한다. 리더가 다운되면 다른 팔로워 중에서 새로운 리더를 선출한다.
- **동기화 :**
  - 팔로워는 리더의 데이터와 주기적으로 동기화 해서, 브로커 장애 시에도 데이터의 손실을 최소화고 서비스를 지속할 수 있다.

### 클러스터 조정

- **메타 데이터 관리 :**
  - 브로커는 토픽, 파티션, 소비자 그룹에 대한 메타 데이터를 관리하며 메세지의 라우팅을 지원한다.
- **컨트롤러 역할 :**
  - 클러스터 내 하나의 브로커가 컨트롤러 역할을 맡아 파티션 리터를 관리하고 관리 작업을 처리한다.



## 카프카 브로커의 아키텍쳐

각 브로커는 고유한 ID로 식별되며 일부 파티션을 담당한다. 이 분포를 통해 카프카는 수평으로 확장할 수 있으며, 더 많은 브로커를 추가하여 부하 증가를 처리할 수 있다.

### Topic

- 카프카에서 데이터를 구분하기 위해 사용하는 단위
- 토픽은 1개 이상의 파티션을 소유하고, 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데 이 데이터를 레코드 라고 부른다.

### Partitions

- 병렬 처리를 가능하게 하는 주제의 세분화
- 카프카 병렬 처리의 핵심으로 컨슈머 그룹으로 묶인 레코드를 병렬로 처리하게 각 컨슈머에 분배한다.
- 각 파티션에 컨슈머 그룹의 한 컨슈머만 배정되고, 이 컨슈머는 카프카 브로커에 offset을 보내서 다음에 받을 레코드를 지정한다. 메세지를 컨슈머에 보내준 다음에 컨슈머가 받았다는 의미로 `commitOffset()` 메세제를 보내면 해당 파티션과 컨슈머 그룹 기준으로 `__consumer_offsets`에 받은 부분까지 지정된다. 만약 컨슈머가 새로 추가 되거나 다운됬다가 재실행되면 파티션이 재할당 되고, Kafka는 `__consumer_offsets`오프셋 기준으로 다시 메세지를 보내도록 한다.

### Offsets

- 파티션 내 메시지에 할당된 순차 ID





## 참고 문헌

- [https://www.redpanda.com/guides/kafka-architecture-kafka-broker](https://www.redpanda.com/guides/kafka-architecture-kafka-broker)
- [https://rudaks.tistory.com/entry/3장-카프카-기본-개념-설명](https://rudaks.tistory.com/entry/3장-카프카-기본-개념-설명)